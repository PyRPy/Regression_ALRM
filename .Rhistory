df <- c(3, 1, 46)
SS1 <- a2$"Sum Sq"
SS <- c(sum(SS1[1:3]), SS1[4], SS1[5])
MS <- SS/df
Fval <- MS/MS[3]
atab <- data.frame(df, SS=round(SS, 0), MS=round(MS, 0), Fval)
row.names(atab) <- c("Regression excluding Tax",
"Tax after others", "Residual")
round(atab, 2)
m3 <- update(m2, ~ . - Tax)
m4 <- update(m3, ~Dlic + Tax + Income + logMiles)
m5 <- update(m3, ~logMiles + Income + Dlic + Tax)
print(anova(m4), signif.stars=FALSE)
print(anova(m5), signif.stars=FALSE)
m1 <- lm(Fuel ~ Tax + Dlic + Income +logMiles, f)
summary(m1)
anova(m1,m2)
round(atab, 2)
print(anova(m4), signif.stars=FALSE)
print(anova(m5), signif.stars=FALSE)
# computations using the fuel data
fuel <- fuel2001  # Not Required in R
fuel$Dlic <- 1000*fuel$Drivers/fuel$Pop
fuel$Fuel <- 1000*fuel$FuelC/fuel$Pop
fuel$Income <- fuel$Income/1000
# use selects the variables of interest including Fuel
m1 <- lm(formula = Fuel ~ Tax + Dlic + Income + log2(Miles), data = fuel)
s1 <- summary(m1)
print(s1, signif.stars=FALSE)
m2 <- update(m1, ~ . -log2(Miles) + log10(fuel$Miles))
summary(m2)
###################################################################
# BGS for BGSgirls only
use <- c(2, 4, 8, 12)
# Fig. 4.1 "../EPS-figs/bgs31.eps"
pairs(BGSgirls[, use])
# print the correlation matrix
print(cor(BGSgirls[, use]), digits=4)
# create linear combinations
BGSgirls$DW9 <- BGSgirls$WT9 - BGSgirls$WT2
BGSgirls$DW18 <- BGSgirls$WT18 - BGSgirls$WT9
BGSgirls$DW218 <- BGSgirls$WT18 - BGSgirls$WT2
m1 <- lm(Soma ~ WT2 + WT9 + WT18 + DW9 + DW18, BGSgirls)
s1 <- summary(m1)
print(s1, signif.stars=FALSE)
m2 <- lm(Soma ~ WT2 + DW9 + DW18 + WT9 + WT18, BGSgirls)
m3 <- lm(Soma ~ WT2 + WT9 + WT18 + DW9 + DW18, BGSgirls)
# use a car function
compareCoefs(m1, m2, m3, se=FALSE)
s2 <- summary(m2)
print(s2, signif.stars=FALSE)
# Pearson and Lee data
lq <- 61
uq <- 64
outer <- with(heights, lq > Mheight | Mheight > uq)
inner <- !outer
m1 <-lm(Dheight ~ Mheight, heights)
m2 <- update(m1, subset=inner)
m3 <- update(m1, subset=outer)
x <- with(heights, c(Mheight[inner], Mheight[outer], Mheight))
y <- with(heights, c(Dheight[inner], Dheight[outer], Dheight))
g <- rep(c("(c) Inner", "(b) Outer","(a) All"),
c(length(which(inner)), length(which(outer)), length(outer)))
# Fig. 4.2
labs <- unique(g)
require(lattice)
xyplot(y~x|factor(g, levels=labs), between=list(y=.32),
panel=
function(x,y,...) { panel.xyplot(x, y, pch=20 ,cex=.3)
panel.lmline(x, y)}, layout=c(1, 3),
xlab="Mother's Height", ylab= "Daughter's Height")
unlist(list(m1=summary(m1)$r.squared,
m2=summary(m2)$r.squared, m3=summary(m3)$r.squared))
# Correlation example
# case 1:  postive bivariate normal
# Fig. 4.3 "../EPS-figs/corr.eps"
cov1 <- matrix(c(1, .7, .7, 1), ncol=2)
cov2 <- matrix(c(1, .00, .00, .08), ncol=2)
cov3 <- matrix(c(1, -.98, -.98, 1), ncol=2)
scov1 <- svd(cov1)$u %*% diag(sqrt(svd(cov1)$d))
scov2 <- svd(cov2)$u %*% diag(sqrt(svd(cov2)$d))
scov3 <- svd(cov3)$u %*% diag(sqrt(svd(cov3)$d))
set.seed(101385)
d <- rnorm(200)
p1 <- matrix(d, ncol=2) %*% t(scov1) %*% diag(c(1, 1))
p2 <- matrix(d, ncol=2) %*% t(scov2) %*% diag(c(1, 3))
p3 <- matrix(d, ncol=2) %*% t(scov3)
#get p4
p4 <- rbind(matrix(2*(.25*rnorm(198) + 1 - 2), ncol=2), matrix(c(4, 4), ncol=2))
# p5
set.seed(101385)
x5 <- 5*(runif(100) - .5)
y5 <- (-x5^2 + 2*x5 + 2*(runif(100) - .5) + 5)/2
p5 <- cbind(x5, y5)
#p6
set.seed(101385)
offset <- rep(c(0, .5, 1, 1.5, 2),c(20, 20, 20, 20, 20))
x6 <- runif(100) + offset
y6 <- -2*x6 + 5*offset
p6 <- cbind(2*(x6 - 2), y6)
d <- rbind(p1, p2, p3, p4, p5, p6)
lab <- c("(a)", "(b)", "(c)", "(d)", "(e)", "(f)")
d <- data.frame(x=d[ , 1],y=d[ , 2],g=factor(rep(lab, rep(100, 6)),
levels=lab[c(5, 6, 3, 4, 1, 2)]))
xyplot(y~x|g, d, scales=list(draw=FALSE), between=list(x=.32, y=.32),
# strip=strip.default(style=2),
panel=
function(x, y, ...) { panel.xyplot(x, y, pch=20 ,cex=.75)
panel.lmline(x, y)},layout=c(2, 3),
xlab=expression(paste("Predictor or ", hat(y))), ylab= "Response")
# sleep data
head(sleep1)
# sleep data
# page 86, table 4.2
head(sleep1)
dim(sleep1)
sleep1
sum(is.na(sleep1))
complete.cases(sleep1)
m1 <- lm(log(SWS) ~ log(BodyWt) + log(Life) + log(GP), data=sleep1,
na.action=na.omit)
m2 <- lm(log(SWS) ~ log(BodyWt)+          log(GP), data=sleep1,
na.action=na.omit)
use.cases <- complete.cases(sleep1)
m3 <- lm(log(SWS) ~ log(BodyWt) + log(Life) + log(GP), data=sleep1,
subset = use.cases)
# writing functions
sum.diff <- function(a, b){
sum <- a + b
diff <- abs(a - b)
c(sum=sum, diff=diff)
}
sum.diff(2, 3)
sum.diff(c(1, 2, 3), c(8, 1, 5))
#############################################################
# Bootstrap
#############################################################
# transactions data
# Fig. 4.4 "../EPS-figs/transact1.eps"
pairs(transact)
#############################################################
# Bootstrap
#############################################################
# transactions data
# Fig. 4.4 "../EPS-figs/transact1.eps"
head(transact)
m1 <- lm(Time ~ T1 + T2, data=transact)
betahat <- coef(m1)
betahat.boot <- boot.case(m1, B=999)
# betahat.boot <- boot.case(m1, B=999)
betahat.boot <- Boot(m1, B=999)
install.packages("boot.case")
?boot
install.packages("boot")
#############################################################
# Bootstrap
#############################################################
# transactions data
# Fig. 4.4 "../EPS-figs/transact1.eps"
head(transact)
# Applied Linear Regression, Third edition
# Chapter 4
# October 14, 2004; revised January 2011 for alr3 Version 2.0, R only
library(alr3)
#############################################################
# Bootstrap
#############################################################
# transactions data
# Fig. 4.4 "../EPS-figs/transact1.eps"
head(transact)
pairs(transact)
m1 <- lm(Time ~ T1 + T2, data=transact)
betahat <- coef(m1)
# betahat.boot <- boot.case(m1, B=999)
betahat.boot <- Boot(m1, B=999)
# betahat.boot <- boot.case(m1, B=999)
betahat.boot <- boot(m1, B=999)
library(boot)
m1 <- lm(Time ~ T1 + T2, data=transact)
betahat <- coef(m1)
# betahat.boot <- boot.case(m1, B=999)
betahat.boot <- boot(m1, B=999)
s1 <- summary(m1)
tval <- qt(.975, s1$df[2])
ans.normal <- data.frame(est = s1$coefficients[,1],
llim= s1$coefficients[,1] - tval*s1$coefficients[,2],
uplim= s1$coefficients[,1] + tval*s1$coefficients[,2])
# Applied Linear Regression, Third edition
# Chapter 5
# October 14, 2004; revised January 2011 for alr3 Version 2.0, R only
require(alr3)
head(physics)
m1 <- lm(y ~ x, weights=1/SD^2, data=physics)
s1 <- summary(m1)
print(s1, signif.stars=FALSE)
print(anova(m1), signif.starts=FALSE)
m2 <- update(m1,   ~ . + I(x^2))
s2 <- summary(m2)
print(s2, signif.stars=FALSE)
print(anova(m2), digits=6)
# Fig. 4.1 "../EPS-figs/fig41.eps"
plot(physics$x, physics$y, xlab=expression(paste("x=", s^(-1/2))),
ylab="Cross section,  y")
abline(m1)
a <- seq(.05, .35, length=50)
lines(a, predict(m2, data.frame(x=a)), lty=2)
#artificial data
x1 <- c(1, 1, 1, 2, 3, 3, 4, 4, 4, 4)
y1 <- c(2.55, 2.75, 2.57, 2.40, 4.19, 4.70, 3.81, 4.87, 2.93, 4.52)
m1 <- lm(y1 ~ x1)
anova(lm(y1 ~ x1 + as.factor(x1), singular.ok=TRUE))
pureErrorAnova(m1)
# short shoot data
a1 <- lm(ybar  ~  Day,  weights=n,  data=longshoots)
# Fig. 5.2 "../EPS-figs/fig42.eps"
plot(ybar ~ Day, longshoots, xlab="Days since dormancy",
ylab="Number of stem units")
abline(a1, lty=2)
print(summary(a1), signif.stars=FALSE)
options(digits=7)
anova(a1)
# general F tests,  in the primer,  but not in the book
fuel <- fuel2001 # make a local copy of the data frame
fuel$Dlic <- 1000*fuel$Drivers/fuel$Pop
fuel$Fuel <- 1000*fuel$FuelC/fuel$Pop
fuel$Income <- fuel$Income/1000
fuel$logMiles <- logb(fuel$Miles, 2)
m1 <- lm(Fuel ~ Dlic + Income + logMiles + Tax,  data=fuel)
m2 <- update(m1,   ~ . - Dlic - Income)
m3 <- update(m2,   ~ . - Tax)
anova(m2, m1)
anova(m3, m2, m1)
# confidence regions for the UN data
#UN2 <- read.table("data/UN2.txt", header=TRUE)
m1 <- lm(logFertility  ~  logPPgdp  +  Purban, UN2)
s1 <- summary(m1)
xtx <- (dim(UN2)[1]-1) * var(UN2[, c(1, 2)])
const <- 2 * s1$sigma * qf(.95, 2, dim(UN2)[1]-3)
bhat <- coef(m1)
confidenceEllipse(m1, Scheffe=TRUE)
# October 14, 2004; revised January 2011 for alr3 Version 2.0, R only
require(alr3)
# quadratic curves in one variable
x <- seq(-1, 1, length=51)
y1 <- -x^2 + 1
y2 <- x^2
z <- data.frame(x=c(x, x), y=c(y1, y2), g=rep(c("(a)", "(b)"), c(51, 51)))
require(lattice)
# Fig. 6.1 "../EPS-figs/quad.eps"
xyplot(y ~ x|g, z, xlab="X", ylab="E(Y|X)", type="l", aspect=1,
between=list(x=.25),
panel = function(x, y){
panel.xyplot(x, y, type="l")
panel.abline(v=.25,  lty=2)
panel.abline(v=.75,  lty=2)},
scales=list(draw=FALSE))
# Oehlert's cake baking data
# Fig. 6.2
with(cakes,
plot(jitter(X1), jitter(X2), xlab=expression(X[1]), ylab=expression(X[2])))
m1 <- lm(Y ~ X1 + X2 + I(X1^2) + I(X2^2) + X1:X2, data=cakes)
# Oehlert's cake baking data
# Fig. 6.2
head(cakes)
m0 <- update(m1, ~ block + .)
# Fig. 6.3 "../EPS-figs/cake2.eps"
oldpar<-par(mfrow=c(1, 2), mar=c(4, 3, 0, .5) + .1, mgp=c(2, 1, 0))
# part (a)
with(cakes,
plot(X1, Y, type="n", xlab=expression(paste("(a)  ", X[1]))) )
X1new <- seq(32, 38, len=50)
lines(X1new, predict(m1, newdata=data.frame(X1=X1new, X2=rep(340, 50))))
lines(X1new, predict(m1, newdata=data.frame(X1=X1new, X2=rep(350, 50))))
lines(X1new, predict(m1, newdata=data.frame(X1=X1new, X2=rep(360, 50))))
text(34, 4.7, "X2=340", adj=0, cex=0.7)
text(32.0, 5.7, "X2=350", adj=0, cex=0.7)
text(32.0, 7.6, "X2=360", adj=0, cex=0.7)
# part (b)
with(cakes,
plot(X2, Y, type="n", xlab=expression(paste("(b)  ", X[2]))))
X2new <- seq(330, 370, len=50)
lines(X2new, predict(m1, newdata=data.frame(X1=rep(33, 50), X2=X2new)))
lines(X2new, predict(m1, newdata=data.frame(X1=rep(35, 50), X2=X2new)))
lines(X2new, predict(m1, newdata=data.frame(X1=rep(37, 50), X2=X2new)))
text(342, 4,   "X1=33", adj=0, cex=0.7)
text(335, 4.55, "X1=35", adj=0, cex=0.7)
text(336, 7.3, "X1=37", adj=0, cex=0.7)
par(oldpar)
m3 <- update(m1,   ~ .-X1:X2)
# Fig. 6.4 "../EPS-figs/cake3.eps"
oldpar<-par(mfrow=c(1, 2), mar=c(4, 3, 0, .5) + .1, mgp=c(2, 1, 0))
# (a)
with(cakes,
plot(X1, Y, type="n", xlab=expression(paste("(a)  ", X[1]))))
X1new <- seq(32, 38, len=50)
lines(X1new, predict(m3, newdata=data.frame(X1=X1new, X2=rep(340, 50))))
lines(X1new, predict(m3, newdata=data.frame(X1=X1new, X2=rep(350, 50))))
lines(X1new, predict(m3, newdata=data.frame(X1=X1new, X2=rep(360, 50))))
text(33, 4.3, "X2=340", adj=0, cex=0.7)
text(32.0, 7.2, "X2=350", adj=0, cex=0.7)
text(34.0, 7.1, "X2=360", adj=0, cex=0.7)
# (b)
with(cakes,
plot(X2, Y, type="n", xlab=expression(paste("(b)  ", X[2]))))
X2new <- seq(330, 370, len=50)
lines(X2new, predict(m3, newdata=data.frame(X1=rep(33, 50), X2=X2new)))
lines(X2new, predict(m3, newdata=data.frame(X1=rep(35, 50), X2=X2new)))
lines(X2new, predict(m3, newdata=data.frame(X1=rep(37, 50), X2=X2new)))
text(340, 4.3,   "X1=33", adj=0, cex=0.7)
text(336, 7.0, "X1=35", adj=0, cex=0.7)
text(346, 7.3, "X1=37", adj=0, cex=0.7)
par(oldpar)
# illustrating poly in the primer
x <- 1:5
print(xmat <- cbind(rep(1, 5), x, x^2, x^3))
qr.Q(qr(xmat))
poly(x, 3)
# delta method stuff in the supplement
m4 <- lm(Y  ~  X2  +  I(X2^2),  data=cakes)
b0 <- coef(m4)[1]
b1 <- coef(m4)[2]
b2 <- coef(m4)[3]
Var <- vcov(m4)
xm <- "-b1/(2*b2)"
xm.expr <- parse(text=xm)
xm.expr
eval(xm.expr)
derivs <- c(D(xm.expr, "b0"), D(xm.expr, "b1"), D(xm.expr, "b2"))
derivs
eval.derivs<-c(eval(D(xm.expr, "b0")), eval(D(xm.expr, "b1")),
eval(D(xm.expr, "b2")))
eval.derivs
sqrt(t(eval.derivs) %*% Var %*% eval.derivs)
deltaMethod(m4, "-b1/(2*b2)")
#sleep1
head(sleep1)
sleep1$D <- factor(sleep1$D) # D is 'danger' level
a1 <- lm(TS ~ D, sleep1, na.action=na.omit)
a0 <- update(a1,  ~ .-1)
compareCoefs(a1, a0)
# Fig. 6.5 "../EPS-figs/sleep11.eps"
plot(sleep1$D, sleep1$TS, xlab="Danger index" , ylab="Total sleep1 (h)")
anova(a0)
anova(a1)
m1 <- lm(TS ~ logb(BodyWt, 2)*D, sleep1, na.action=na.omit)
m2 <- update(m1,   ~ D  +  logb(BodyWt, 2))
m4 <- update(m1,   ~ logb(BodyWt, 2))
m3 <- update(m1,   ~ logb(BodyWt, 2):D)
compareCoefs(m1, m2, m4, m3, se=FALSE)
# all have the same Residual sum of squares:
a1<-anova(m4, m1)
a2<-anova(m3, m1)
a3<-anova(m2, m1)
a1[2, ]; a2[2, ]; a3[2, ]
# Figure with lattice fitting all four models.
n1 <- lm(TS ~ -1 + D + D:logb(BodyWt, 2), sleep1, na.action=na.omit)
n2 <- update(m1,   ~ -1 + D  +  logb(BodyWt, 2))
n4 <- update(m1,   ~ logb(BodyWt, 2))
n3 <- update(m1,   ~ logb(BodyWt, 2):D)
d <- rbind(sleep1, sleep1, sleep1, sleep1)
labels <- c("(a) General",  "(b) Parallel", "(c) Common intercept",  "(d) Common regression")
d$f <- rep(c(1, 2, 3, 4),  rep(62, 4))
d$fig <- rep(labels,  rep(62, 4))
# Fig. 6.6 "../EPS-figs/sleeplines.eps"
xyplot(TS ~ logb(BodyWt, 2)|fig, group=D,  d,  subscripts=TRUE, ID=d$f,
as.table=TRUE,  key=simpleKey(as.character(1:5), FALSE, FALSE, T),
xlab=expression(log[2](BodyWt)),  cex=.75,  between=list(x=.32, y=.32),
panel = function(x, y, groups, subscripts, ID){
panel.superpose(x, y, groups=groups, subscripts=subscripts,
pch=as.character(1:5))
g <- unique(ID[subscripts]) # which panel
if(g==1) {panel.abline(coef(n1)[c(1, 6)], lty=1)
panel.abline(coef(n1)[c(2, 7)], lty=2)
panel.abline(coef(n1)[c(3, 8)], lty=3)
panel.abline(coef(n1)[c(4, 9)], lty=4)
panel.abline(coef(n1)[c(5, 10)], lty=5)}
if(g==3) {panel.abline(coef(n3)[c(1, 2)], lty=1)
panel.abline(coef(n3)[c(1, 3)], lty=2)
panel.abline(coef(n3)[c(1, 4)], lty=3)
panel.abline(coef(n3)[c(1, 5)], lty=4)
panel.abline(coef(n3)[c(1, 6)], lty=5)}
if(g==2) {panel.abline(coef(n2)[c(1, 6)], lty=1)
panel.abline(coef(n2)[c(2, 6)], lty=2)
panel.abline(coef(n2)[c(3, 6)], lty=3)
panel.abline(coef(n2)[c(4, 6)], lty=4)
panel.abline(coef(n2)[c(5, 6)], lty=5)}
if(g==4) {panel.abline(coef(n4)[c(1, 2)], lty=1)}
})
# Partial 1D models
# Fig. 6.7
# relabel sex  from 0 and1 to male and female
ais$Sex <- factor(c("male", "female")[ais$Sex + 1])
# Partial 1D models
# Fig. 6.7
# relabel sex  from 0 and1 to male and female
head(ais)
scatterplotMatrix(~ LBM + Ht +Wt + RCC|Sex, data=ais)
pairs(ais[, c(4, 2, 3, 5)], pch=char[1 + ais$Sex], cex=.85)
pairs(ais[, c(4, 2, 3, 5)], pch=char[1 + ais$Sex], cex=.85)
pairs(ais[, c(4, 2, 3, 5)], pch=as.character(1 + ais$Sex), cex=.85)
pairs(ais[, c(4, 2, 3, 5)])
m <- pod(LBM ~ Ht + Wt + RCC,  data=ais,  group=Sex)
anova(m)
# Not in the text "../EPS-figs/supp61.eps"
plot(m, pch=c("m", "f"), colors=c("red", "black"))
# Random coef. models
library(nlme)
# Fig. 6.9 "../EPS-figs/chloride1.eps"
xyplot(Cl ~ Month|Type,  group=Marsh,  data=chloride, ylab="Cl (mg/l)",
xlab="Month number", type=c("g", "p", "l"))
m1 <- lme(Cl ~ Month + Type,  data=chloride,  random= ~ 1 + Type|Marsh)
m2 <- update(m1,  random= ~ 1|Marsh)
anova(m1, m2)
intervals(m2)
setwd("~/GitHub/Regression_STAT501")
martian <- read.csv("DataL10/martian.csv", header=T)
head(martian)
attach(martian)
model.1 <- lm(weight ~ height + water)
summary(model.1)
pairs(weigt ~ height, water)
pairs(weigt ~ height + water)
pairs(~ weigt + height + water)
pairs(martian)
model.2 <- lm(weight ~ height)
summary(model.2)
plot(x=height, y=weight, col=water/10+1,
panel.last = c(lines(sort(height[water==0]),
fitted(model.1)[water==0][order(height[water==0])],
col=1),
lines(sort(height[water==10]),
fitted(model.1)[water==10][order(height[water==10])],
col=2),
lines(sort(height[water==20]),
fitted(model.1)[water==20][order(height[water==20])],
col=3),
lines(sort(height), fitted(model.2)[order(height)], col=4)))
legend("topleft", col=1:4, pch=1, lty=1, inset=0.02,
legend=c("Model 1, water=0", "Model 1, water=10",
"Model 1, water=20", "Model 2"))
detach(martian)
cement <- read.table("DataL10/cement.txt", header=T)
attach(cement)
pairs(cement, lower.panel = NULL)
model.0 <- lm(y ~ 1)
add1(model.0, ~ x1 + x2 + x3 + x4, test="F")
model.4 <- lm(y ~ x4)
add1(model.4, ~ . + x1 + x2 + x3, test="F")
model.14 <- lm(y ~ x1 + x4)
drop1(model.14, ~ ., test="F")
add1(model.14, ~ . + x2 + x3, test="F")
model.124 <- lm(y ~ x1 + x2 + x4)
drop1(model.124, ~ ., test="F")
model.12 <- lm(y ~ x1 + x2)
add1(model.12, ~ . + x3 + x4, test="F")
detach(cement)
summary(model.124)
?drop1
iqsize <- read.table("DataL10/iqsize.txt", header=T)
attach(iqsize)
pairs(iqsize, lower.panel = NULL)
model.0 <- lm(PIQ ~ 1)
add1(model.0, ~ Brain + Height + Weight, test="F")
model.1 <- lm(PIQ ~ Brain)
add1(model.1, ~ . + Height + Weight, test="F")
model.12 <- lm(PIQ ~ Brain + Height)
drop1(model.12, ~ ., test="F")
add1(model.12, ~ . + Weight, test="F")
detach(iqsize)
bloodpress <- read.table("DataL10/bloodpress.txt", header=T)
attach(bloodpress)
pairs(bloodpress[,c(2:5)])
pairs(bloodpress[,c(2,6:8)])
model.0 <- lm(BP  ~ 1)
add1(model.0, ~ Age + Weight + BSA + Dur + Pulse + Stress, test="F")
model.2 <- lm(BP ~ Weight)
add1(model.2, ~ . + Age + BSA + Dur + Pulse + Stress, test="F")
model.12 <- lm(BP ~ Age + Weight)
drop1(model.12, ~ ., test="F")
add1(model.12, ~ . + BSA + Dur + Pulse + Stress, test="F")
model.123 <- lm(BP ~ Age + Weight + BSA)
drop1(model.123, ~ ., test="F")
add1(model.123, ~ . + Dur + Pulse + Stress, test="F")
detach(bloodpress)
cement <- read.table("DataL10/cement.txt", header=T)
attach(cement)
library(leaps)
subset <- regsubsets(y ~ x1 + x2 + x3 + x4, method="exhaustive", nbest=2, data=cement)
cbind(summary(subset)$outmat, round(summary(subset)$adjr2, 3), round(summary(subset)$cp, 1))
model.1234 <- lm(y ~ x1 + x2 + x3 + x4)
model.12 <- lm(y ~ x1 + x2)
SSE.k <- sum(residuals(model.12)^2) # SSE_k = 57.90448
MSE.all <- summary(model.1234)$sigma^2 # MSE_all = 5.982955
params <- summary(model.12)$df[1] # k+1 = 3
n <- sum(summary(model.1234)$df[1:2]) # n = 13
SSE.k/MSE.all + 2*params - n # Cp = 2.678242
model.14 <- lm(y ~ x1 + x4)
SSE.k <- sum(residuals(model.14)^2) # SSE_k = 74.76211
params <- summary(model.14)$df[1] # k+1 = 3
SSE.k/MSE.all + 2*params - n # Cp = 5.495851
model.124 <- lm(y ~ x1 + x2 + x4)
library(car)
vif(model.124)
summary(model.12)
vif(model.12)
plot(x=fitted(model.12), y=rstandard(model.12),
panel.last = abline(h=0, lty=2))
qqnorm(rstandard(model.12), main="", datax=TRUE)
qqline(rstandard(model.12), datax=TRUE)
library(nortest)
ad.test(rstandard(model.12)) # A = 0.6136, p-value = 0.08628
detach(cement)
